{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a053cf3",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "## - Import libraries and define functions + Initial setup\n",
    "\n",
    "## - Pre-process files\n",
    "\n",
    "## - Make table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf950391",
   "metadata": {},
   "source": [
    "# Import libraries and define functions + Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbddefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f624b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: fix_column_names\n",
    "\n",
    "purpose: Fixing the column names, making them smaller, informative, and consistent\n",
    "\n",
    "input: The raw counts dataframe for either genes or transcripts \n",
    "\n",
    "output: Same dataframe with improved column names\n",
    "'''\n",
    "\n",
    "def fix_column_names(df, is_gene=False):\n",
    "    \n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Check if this is a gene counts object\n",
    "    if is_gene:\n",
    "        \n",
    "        ## Get count column names and create list of new column names\n",
    "        count_columns = dff.columns.tolist()\n",
    "        list_new_names = [\"gene_id\"]\n",
    "        \n",
    "        ## gene_id comes in as index for gene counts data, make it into the first column instead\n",
    "        dff[\"gene_id\"] = dff.index\n",
    "        cols = list(dff.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        dff = dff[cols]\n",
    "        dff.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    ## If it is a transcript dataset\n",
    "    else:\n",
    "        ## Set count columns and create list of new names\n",
    "        count_columns = dff.columns[2:].tolist()\n",
    "        list_new_names = [ \"transcript_id\", \"gene_id\"]\n",
    "    \n",
    "    ## Fix names one by one and add to list of new names\n",
    "    for col in count_columns:\n",
    "        col = col.split(\"_mapped\")[0] + \"_counts\"\n",
    "        list_new_names.append(col)\n",
    "    \n",
    "    ## Rename columns\n",
    "    dff.columns = list_new_names\n",
    "    \n",
    "    return dff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88fff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: parse_df_columns\n",
    "\n",
    "purpose: parsing the last aggregate column of the gtf/gff3 into useful columns and cleaning non-relevant columns\n",
    "\n",
    "input: dataframe containining \"raw\" gtf/gff\n",
    "\n",
    "output: dataframe containing gtf with useful columns [\"gene_id\", \"transcript_id\", etc...]\n",
    "'''\n",
    "\n",
    "def parse_df_columns(df, is_ref=True, is_transcript=False, is_prot=False, delete_other=True):\n",
    "\n",
    "    if is_ref:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "        \n",
    "        ## Get gene names\n",
    "        df[\"gene_name\"] = df[\"other\"].str.split(\"gene_name \\\"\", expand=True)[1].str.split('\\\";', expand=True)[0]\n",
    "        \n",
    "        ## Get get transcript biotype\n",
    "        df[\"gene_biotype\"] = df[\"other\"].str.split('gene_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        ## If is transcript get transcript id and transcript biotype\n",
    "        if is_transcript:\n",
    "            df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            df[\"transcript_biotype\"] = df[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            \n",
    "            ## If is prot get protein_id\n",
    "            if is_prot:\n",
    "                df[\"protein_id\"] = df[\"other\"].str.split('protein_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"ccds_id\"] = df[\"other\"].str.split('ccds_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "\n",
    "        ## Get transcript ids\n",
    "        df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Get exon number\n",
    "        df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        if delete_other:\n",
    "            df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df.loc[df[col].isnull(), col] = np.NaN\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562cb98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function loads all salmon quant.sh files with the given filename from all subdirectories \n",
    "of the provided parent directory and returns a merged counts and a merged TPM matrix.\n",
    "\n",
    "Parameters:\n",
    "filename (str): The name of the salmon file to load\n",
    "parent_directory (str): The path to the parent directory containing the folders with salmon quant.sf files.\n",
    "\n",
    "Returns:\n",
    "list: A merged counts and a merged TPM matrix.\n",
    "\"\"\"\n",
    "    \n",
    "def load_salmon_data_and_merge(filename, parent_directory):\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    # Create a path pattern to find all folders containing the TSV files\n",
    "    folder_pattern = os.path.join(parent_directory, '*', filename)\n",
    "\n",
    "    # Get a list of all TSV files matching the pattern\n",
    "    tsv_files = glob.glob(folder_pattern)\n",
    "    \n",
    "    ## Create flag for first iteration of loop\n",
    "    flag_first = True\n",
    "    \n",
    "    # Read each TSV file into a DataFrame and append it to the list\n",
    "    for tsv_file in tsv_files:\n",
    "        \n",
    "        ## Create column names\n",
    "        sample_name = tsv_file.split(\"/\")[-2].split(\"_Aligned\")[0]\n",
    "        tpm_name = sample_name + \"_TPM\"\n",
    "        counts_name = sample_name + \"_counts\"\n",
    "        \n",
    "        ## Open dataframe for counts and TPM\n",
    "        df_counts = pd.read_csv(tsv_file, sep='\\t', usecols=[0, 4], names=[\"transcript_id\", counts_name],\n",
    "                               low_memory=False, header=0)\n",
    "        df_tpm = pd.read_csv(tsv_file, sep='\\t', usecols=[0, 3], names=[\"transcript_id\", tpm_name], \n",
    "                             low_memory=False, header=0)\n",
    "                \n",
    "        ## If it is not the first iteration just add to merged dataframes\n",
    "        if flag_first == False:\n",
    "            \n",
    "            df_meged_counts = df_meged_counts.merge(df_counts, on=\"transcript_id\", how=\"inner\")\n",
    "            df_meged_tpm = df_meged_tpm.merge(df_tpm, on=\"transcript_id\", how=\"inner\")\n",
    "        \n",
    "        ## If it is the first iteration set merged dataframe to first dataframes\n",
    "        ## Set flag_first to false\n",
    "        else:\n",
    "            \n",
    "            df_meged_counts = df_counts.copy()\n",
    "            df_meged_tpm = df_tpm.copy()\n",
    "            \n",
    "            flag_first = False\n",
    "            \n",
    "        df_meged_counts.shape\n",
    "           \n",
    "\n",
    "    return df_meged_counts, df_meged_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97fa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define ggplot colors\n",
    "ggplot2_colors = [\"#F8766D\", \"#CD9600\", \"#7CAE00\", \"#00BE67\", \"#00BFC4\", \"#00A9FF\", \"#C77CFF\", \"#FF61CC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74817c06",
   "metadata": {},
   "source": [
    "## - Pre-process files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f1d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parent directory and salmon quantification file name\n",
    "parent_dir = \"../../../data/raw/1st_rebuttal_data/ROSMAP_illumina_DorsoLateralPreFrontalCortex_UNIQUE/salmon_alignment_mode/\"\n",
    "name = \"quant.sf\"\n",
    "\n",
    "## Create merged dataframe with counts and tpm\n",
    "df_counts_unique_rosmap, df_tpm_unique = load_salmon_data_and_merge(name, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f71704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parent directory and salmon quantification file name\n",
    "parent_dir = \"../../../data/raw/1st_rebuttal_data/CSHL_illumina_uky_aged_brain_with_our_extended_annotation_UNIQUE/salmon_alignment_mode/\"\n",
    "name = \"quant.sf\"\n",
    "\n",
    "## Create merged dataframe with counts and tpm\n",
    "df_counts_unique_ours, df_tpm_unique = load_salmon_data_and_merge(name, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccfa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open up unique reads\n",
    "df_counts_unique_gtex = pd.read_csv(\"../../../data/raw/1st_rebuttal_data/GTEX_with_our_extended_annotation_quant/bambu_quant/uniqueCounts_transcript.txt\",\n",
    "                              sep=\"\\t\")\n",
    "\n",
    "## Only keep BA9 brain samples\n",
    "## Excluded BA9 sample \"GTEX-T5JC-0011-R10A-SM-2TT23.FAK91589\" because it had only 46331 reads.\n",
    "df_counts_unique_gtex = df_counts_unique_gtex[[\"TXNAME\", \"GENEID\",\"GTEX-1192X-0011-R10a-SM-4RXXZ.FAK49046_mapped_filtered_sorted\",\n",
    "                  \"GTEX-13X6J-0011-R10b-SM-5CEKT.FAK44896_mapped_filtered_sorted\",\n",
    "                  \"GTEX-14BIL-0011-R10a-SM-5EQV4.FAK49209_mapped_filtered_sorted\",\n",
    "                  \"GTEX-QDT8-0011-R10A-SM-2FKJB.FAK49182_mapped_filtered_sorted\",\n",
    "                  \"GTEX-15DCD-0011-R10b-SM-5S51M.FAK42101_mapped_filtered_sorted\"]]\n",
    "\n",
    "## Fix column names\n",
    "df_counts_unique_gtex = fix_column_names(df_counts_unique_gtex, is_gene=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680e26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate total counts for each dataframe\n",
    "df_counts_unique_rosmap[\"total_unique_counts_ROSMAP_short-reads\"] = df_counts_unique_rosmap[df_counts_unique_rosmap.filter(regex='count').columns].sum(axis=1)\n",
    "df_counts_unique_ours[\"total_unique_counts_OURS_short-reads\"] = df_counts_unique_ours[df_counts_unique_ours.filter(regex='count').columns].sum(axis=1)\n",
    "df_counts_unique_gtex[\"total_unique_counts_GTEx_long-reads\"] = df_counts_unique_gtex[df_counts_unique_gtex.filter(regex='count').columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd6294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep only relevant columns\n",
    "df_counts_unique_rosmap = df_counts_unique_rosmap[[\"transcript_id\", \"total_unique_counts_ROSMAP_short-reads\"]].copy()\n",
    "df_counts_unique_ours = df_counts_unique_ours[[\"transcript_id\", \"total_unique_counts_OURS_short-reads\"]].copy()\n",
    "df_counts_unique_gtex = df_counts_unique_gtex[[\"transcript_id\", \"total_unique_counts_GTEx_long-reads\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1151b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge dataframes\n",
    "df = df_counts_unique_rosmap.merge(df_counts_unique_ours, on=\"transcript_id\", how=\"inner\")\n",
    "df = df.merge(df_counts_unique_gtex, on=\"transcript_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd888fa",
   "metadata": {},
   "source": [
    "## - Make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f12ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep new transcripts\n",
    "df = df.loc[df[\"transcript_id\"].str.startswith(\"Bambu\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381183d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import names of high_confidence (hf) new transcript\n",
    "hf_transcripts = pd.read_csv(\"../../../references/high_confidence_transcripts.tsv\", sep=\"\\t\")\n",
    "\n",
    "## Create high-confidence transcript flag\n",
    "condition = df[\"transcript_id\"].isin(hf_transcripts[\"transcript_id\"])\n",
    "\n",
    "df.loc[condition, \"is_high-confidence\"] = True\n",
    "df.loc[~condition, \"is_high-confidence\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d9dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and parse through extended annotations\n",
    "ref = pd.read_csv(\"../../../data/raw/nextflow_pipeline_output/bambu_discovery/extended_annotations.gtf\", header=None, delimiter=\"\\t\",\n",
    "                        low_memory=False, comment=\"#\", names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"])\n",
    "\n",
    "## Take away ERCCs\n",
    "ref = ref.loc[~ref[\"chr\"].str.startswith(\"ERCC-\")]\n",
    "\n",
    "## Parse\n",
    "ref = parse_df_columns(ref, is_ref=False)\n",
    "\n",
    "## Only keep transcripts\n",
    "ref_transcripts = ref.loc[ref[\"type\"] == \"transcript\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a920e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add chromosome and gene_id\n",
    "df = df.merge(ref_transcripts[[\"gene_id\", \"transcript_id\", \"chr\"]], on=\"transcript_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1306f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add gene names and fill gene_name with gene_id for genes with no name\n",
    "\n",
    "gene_names = pd.read_csv(\"../../../references/gene_names.tsv\", sep=\"\\t\")\n",
    "\n",
    "df = df.merge(gene_names, on=[\"gene_id\", \"chr\"], how=\"left\")\n",
    "\n",
    "df['gene_name'].fillna(df['gene_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "414fba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Type column to define type of transcript discovery\n",
    "\n",
    "df.loc[df[\"gene_id\"].str.startswith(\"Bambu\"), \"discovery_category\"] = \"New from new\"\n",
    "df.loc[~df[\"gene_id\"].str.startswith(\"Bambu\"), \"discovery_category\"] =  \"New from known\"\n",
    "df.loc[df[\"chr\"] == \"MT\", \"discovery_category\"] = \"New from mito\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ed10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorder columns\n",
    "\n",
    "new_col_order = ['chr', 'gene_id', 'gene_name', 'transcript_id', 'discovery_category', 'is_high-confidence',\n",
    "                 'total_unique_counts_ROSMAP_short-reads', 'total_unique_counts_OURS_short-reads',\n",
    "                 'total_unique_counts_GTEx_long-reads']\n",
    "\n",
    "\n",
    "df = df[new_col_order].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c72c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save table!\n",
    "\n",
    "df.to_csv(\"../../../data/processed/1st_rebuttal/new_transcript_unique_support/new_transcripts_unique_support.tsv\",\n",
    "         sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
