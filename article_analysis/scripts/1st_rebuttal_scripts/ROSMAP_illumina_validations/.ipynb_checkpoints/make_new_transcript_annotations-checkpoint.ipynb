{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ae2990",
   "metadata": {},
   "source": [
    "# Import libraries and define functions + Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f335a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1eedbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: fix_column_names\n",
    "\n",
    "purpose: Fixing the column names, making them smaller, informative, and consistent\n",
    "\n",
    "input: The raw counts dataframe for either genes or transcripts \n",
    "\n",
    "output: Same dataframe with improved column names\n",
    "'''\n",
    "\n",
    "def fix_column_names(df, is_gene=False):\n",
    "    \n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Check if this is a gene counts object\n",
    "    if is_gene:\n",
    "        \n",
    "        ## Get count column names and create list of new column names\n",
    "        count_columns = dff.columns.tolist()\n",
    "        list_new_names = [\"gene_id\"]\n",
    "        \n",
    "        ## gene_id comes in as index for gene counts data, make it into the first column instead\n",
    "        dff[\"gene_id\"] = dff.index\n",
    "        cols = list(dff.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        dff = dff[cols]\n",
    "        dff.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    ## If it is a transcript dataset\n",
    "    else:\n",
    "        ## Set count columns and create list of new names\n",
    "        count_columns = dff.columns[2:].tolist()\n",
    "        list_new_names = [ \"transcript_id\", \"gene_id\"]\n",
    "    \n",
    "    ## Fix names one by one and add to list of new names\n",
    "    for col in count_columns:\n",
    "        col = col.split(\"_mapped\")[0] + \"_counts\"\n",
    "        list_new_names.append(col)\n",
    "    \n",
    "    ## Rename columns\n",
    "    dff.columns = list_new_names\n",
    "    \n",
    "    return dff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad6a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: parse_df_columns\n",
    "\n",
    "purpose: parsing the last aggregate column of the gtf/gff3 into useful columns and cleaning non-relevant columns\n",
    "\n",
    "input: dataframe containining \"raw\" gtf/gff\n",
    "\n",
    "output: dataframe containing gtf with useful columns [\"gene_id\", \"transcript_id\", etc...]\n",
    "'''\n",
    "\n",
    "def parse_df_columns(df, is_ref=True, is_transcript=False, is_prot=False, delete_other=True):\n",
    "\n",
    "    if is_ref:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "        \n",
    "        ## Get gene names\n",
    "        df[\"gene_name\"] = df[\"other\"].str.split(\"gene_name \\\"\", expand=True)[1].str.split('\\\";', expand=True)[0]\n",
    "        \n",
    "        ## Get get transcript biotype\n",
    "        df[\"gene_biotype\"] = df[\"other\"].str.split('gene_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        ## If is transcript get transcript id and transcript biotype\n",
    "        if is_transcript:\n",
    "            df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            df[\"transcript_biotype\"] = df[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            \n",
    "            ## If is prot get protein_id\n",
    "            if is_prot:\n",
    "                df[\"protein_id\"] = df[\"other\"].str.split('protein_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"ccds_id\"] = df[\"other\"].str.split('ccds_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "\n",
    "        ## Get transcript ids\n",
    "        df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Get exon number\n",
    "        df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        if delete_other:\n",
    "            df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df.loc[df[col].isnull(), col] = np.NaN\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927d335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: calculate_cpm\n",
    "\n",
    "purpose: Calculate CPM for the each sample given\n",
    "\n",
    "input: Counts dataset\n",
    "\n",
    "output: Counts dataset with CPM columns as well\n",
    "'''\n",
    "\n",
    "def calculate_cpm(df, is_gene=False):\n",
    "    \n",
    "    dff = df.copy()\n",
    "\n",
    "    ## Set count columns if dataframe is gene counts\n",
    "    if is_gene:\n",
    "        count_columns = dff.columns[1:].tolist()\n",
    "    \n",
    "    ## Set count columns if dataframe is transcript counts\n",
    "    else:\n",
    "        count_columns = dff.columns[2:].tolist()\n",
    "\n",
    "    ## Loop through counts columns to calculate CPM and add to the dataframe\n",
    "    for col in count_columns:\n",
    "        \n",
    "        dff[col] = round(dff[col], 2)\n",
    "        cpm_name = col.replace(\"_counts\", \"_CPM\")\n",
    "        dff[cpm_name] = round(((dff[col]/(dff[col].sum())) * 1000000), 2)\n",
    "    \n",
    "    return dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62833f",
   "metadata": {},
   "source": [
    "# - Create high-confidence annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0238d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data for transcript level counts and fix column names\n",
    "\n",
    "df = pd.read_csv(\"../../../data/raw/nextflow_pipeline_output/bambu_discovery/counts_transcript.txt\", \n",
    "                           delimiter=\"\\t\", low_memory=False, header=0)\n",
    "\n",
    "df = fix_column_names(df, is_gene=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d77add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate CPM and drop count columns\n",
    "df = calculate_cpm(df, is_gene=False)\n",
    "\n",
    "df = df[df.columns.drop(list(df.filter(regex='counts')))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c939cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate median CPM\n",
    "df[\"median_CPM\"] = df[df.filter(regex='[0-9]_CPM').columns].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a493dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe with only new transcripts\n",
    "df_new = df.loc[df[\"transcript_id\"].str.startswith(\"Bambu\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8a4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe with new high-confidence transcripts\n",
    "df_new_high_confidence = df_new.loc[df_new[\"median_CPM\"] > 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354aa718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and parse through extended annotations\n",
    "ref = pd.read_csv(\"../../../data/raw/nextflow_pipeline_output/bambu_discovery/extended_annotations.gtf\", header=None, delimiter=\"\\t\",\n",
    "                        low_memory=False, comment=\"#\", names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"])\n",
    "\n",
    "ref = ref.loc[~ref[\"chr\"].str.startswith(\"ERCC-\")]\n",
    "\n",
    "ref = parse_df_columns(ref, is_ref=False)\n",
    "\n",
    "ref_transcripts = ref.loc[ref[\"type\"] == \"transcript\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ac4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open original reference\n",
    "original_ref = pd.read_csv(\"../../../references/Homo_sapiens.GRCh38.107_ERCC.gtf\", header=None, delimiter=\"\\t\", low_memory=False, \n",
    "                       names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"], comment=\"#\")\n",
    "\n",
    "original_ref = original_ref.loc[~original_ref[\"chr\"].str.startswith(\"ERCC-\")]\n",
    "\n",
    "## Parse through reference to get gene names and ids\n",
    "orig_ref = original_ref.loc[original_ref[\"type\"]==\"gene\"].copy()\n",
    "orig_ref = parse_df_columns(orig_ref, is_ref=True)\n",
    "\n",
    "## Create gene names dataframe\n",
    "gene_names = orig_ref[[\"gene_name\", \"gene_id\", \"chr\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea414b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add chromosome to list and remove mito transcripts\n",
    "\n",
    "df_new_high_confidence = df_new_high_confidence.merge(ref_transcripts[[\"transcript_id\", \"chr\"]], how=\"inner\", on=\"transcript_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c9eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of high confidence mitochondrial transcripts\n",
    "list_mito_high_confidence = [\"BambuTx1845\", \"BambuTx1846\", \"BambuTx1847\", \"BambuTx1848\", \"BambuTx1850\"]\n",
    "\n",
    "df_mito_high_confidence = df_new_high_confidence.loc[df_new_high_confidence[\"transcript_id\"].isin(\n",
    "                                                                                list_mito_high_confidence)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c09ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all mitochondrial transcripts from high-confidence\n",
    "df_new_high_confidence = df_new_high_confidence.loc[df_new_high_confidence[\"chr\"] != \"MT\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f911e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add back only the truly high-confidence mitochondrial transcripts\n",
    "df_new_high_confidence = pd.concat([df_new_high_confidence, df_mito_high_confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0336c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove counts columns\n",
    "df_new_high_confidence = df_new_high_confidence.drop(columns=df_new_high_confidence.filter(like='_CPM').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "781b5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add gene_name column\n",
    "df_new_high_confidence = df_new_high_confidence.merge(gene_names, on=[\"gene_id\", \"chr\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3034974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorganize column order\n",
    "df_new_high_confidence = df_new_high_confidence[[\"chr\", \"gene_name\", \"gene_id\", \"transcript_id\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1ec7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NAs in gene_name with gene_id\n",
    "df_new_high_confidence['gene_name'].fillna(df_new_high_confidence['gene_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc405907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save high_confidence transcript names and info\n",
    "df_new_high_confidence.to_csv(\"../../../references/high_confidence_transcripts.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09017da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save gene names for ease of use\n",
    "gene_names.to_csv(\"../../../references/gene_names.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54b345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
