{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9928c02",
   "metadata": {},
   "source": [
    "# Import libraries and define functions + Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7c2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import csv\n",
    "\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27e634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "name: relative_transcript_abundance\n",
    "\n",
    "purpose: calculate relative transcript abundance\n",
    "\n",
    "input: a dataframe with a ref_gene_id column identifying the transcript gene of origin and a cov columns with \n",
    "the coverage for the transcripts.\n",
    "\n",
    "output: the same dataframe with a relative abundance column added\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def relative_transcript_abundance(df):\n",
    "    \n",
    "    ## Group by gene_id and get total expression for each gene (not counting introns)\n",
    "    df_sums = df[[\"gene_id\", \"total_CPM\"]].groupby(\"gene_id\").sum()\n",
    "    df_sums[\"total_CPM_gene\"] = df_sums[\"total_CPM\"]\n",
    "    df_sums.drop(columns=\"total_CPM\", inplace=True)\n",
    "    \n",
    "    ## Merge dataframe with total gene level CPM with regular transcript level CPM dataframe\n",
    "    merged_df = pd.merge(df, df_sums, how='inner', on=\"gene_id\")\n",
    "    \n",
    "    ## Calculater relative percent abundance for each transcript within its gene\n",
    "    merged_df[\"relative_abundance_percent\"] = ((merged_df[\"total_CPM\"]/merged_df[\"total_CPM_gene\"]) * 100)\n",
    "    \n",
    "    ## Rename total_CPM for transcript column\n",
    "    merged_df[\"total_CPM_transcript\"] = merged_df[\"total_CPM\"]\n",
    "    merged_df.drop(columns=\"total_CPM\", inplace=True)\n",
    "\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6446e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: fix_column_names\n",
    "\n",
    "purpose: Fixing the column names, making them smaller, informative, and consistent\n",
    "\n",
    "input: The raw counts dataframe for either genes or transcripts \n",
    "\n",
    "output: Same dataframe with improved column names\n",
    "'''\n",
    "\n",
    "def fix_column_names(df, is_gene=False):\n",
    "    \n",
    "    ## Check if this is a gene counts object\n",
    "    if is_gene:\n",
    "        \n",
    "        ## Get count column names and create list of new column names\n",
    "        count_columns = df.columns.tolist()\n",
    "        list_new_names = [\"gene_id\"]\n",
    "        \n",
    "        ## gene_id comes in as index for gene counts data, make it into the first column instead\n",
    "        df[\"gene_id\"] = df.index\n",
    "        cols = list(df.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        df = df[cols]\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    ## If it is a transcript dataset\n",
    "    else:\n",
    "        ## Set count columns and create list of new names\n",
    "        count_columns = df.columns[2:].tolist()\n",
    "        list_new_names = [ \"transcript_id\", \"gene_id\"]\n",
    "    \n",
    "    ## Fix names one by one and add to list of new names\n",
    "    for col in count_columns:\n",
    "        col = col.split(\"_mapped\")[0] + \"_counts\"\n",
    "        list_new_names.append(col)\n",
    "    \n",
    "    ## Rename columns\n",
    "    df.columns = list_new_names\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143176a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: parse_df_columns\n",
    "\n",
    "purpose: parsing the last aggregate column of the gtf/gff3 into useful columns and cleaning non-relevant columns\n",
    "\n",
    "input: dataframe containining \"raw\" gtf/gff\n",
    "\n",
    "output: dataframe containing gtf with useful columns [\"gene_id\", \"transcript_id\", etc...]\n",
    "'''\n",
    "\n",
    "def parse_df_columns(df, is_ref=True, is_transcript=False, is_prot=False, delete_other=True):\n",
    "\n",
    "    if is_ref:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "        \n",
    "        ## Get gene names\n",
    "        df[\"gene_name\"] = df[\"other\"].str.split(\"gene_name \\\"\", expand=True)[1].str.split('\\\";', expand=True)[0]\n",
    "        \n",
    "        ## Get get transcript biotype\n",
    "        df[\"gene_biotype\"] = df[\"other\"].str.split('gene_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        ## If is transcript get transcript id and transcript biotype\n",
    "        if is_transcript:\n",
    "            df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            df[\"transcript_biotype\"] = df[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            \n",
    "            ## If is prot get protein_id\n",
    "            if is_prot:\n",
    "                df[\"protein_id\"] = df[\"other\"].str.split('protein_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"ccds_id\"] = df[\"other\"].str.split('ccds_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "\n",
    "        ## Get transcript ids\n",
    "        df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Get exon number\n",
    "        df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        if delete_other:\n",
    "            df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df.loc[df[col].isnull(), col] = np.NaN\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1117a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: calculate_cpm\n",
    "\n",
    "purpose: Calculate CPM for the each sample given\n",
    "\n",
    "input: Counts dataset\n",
    "\n",
    "output: Counts dataset with CPM columns as well\n",
    "'''\n",
    "\n",
    "def calculate_cpm(df, is_gene=False):\n",
    "\n",
    "    ## Set count columns if dataframe is gene counts\n",
    "    if is_gene:\n",
    "        count_columns = df.columns[1:].tolist()\n",
    "    \n",
    "    ## Set count columns if dataframe is transcript counts\n",
    "    else:\n",
    "        count_columns = df.columns[2:].tolist()\n",
    "\n",
    "    ## Loop through counts columns to calculate CPM and add to the dataframe\n",
    "    for col in count_columns:\n",
    "        \n",
    "        df[col] = round(df[col], 2)\n",
    "        cpm_name = col.replace(\"_counts\", \"_CPM\")\n",
    "        df[cpm_name] = round(((df[col]/(df[col].sum())) * 1000000), 2)\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed11391",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define ggplot colors\n",
    "ggplot2_colors = [\"#F8766D\", \"#CD9600\", \"#7CAE00\", \"#00BE67\", \"#00BFC4\", \"#00A9FF\", \"#C77CFF\", \"#FF61CC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f349db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open original reference\n",
    "original_ref = pd.read_csv(\"../../references/Homo_sapiens.GRCh38.107_ERCC.gtf\", header=None, delimiter=\"\\t\", low_memory=False, \n",
    "                       names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"], comment=\"#\")\n",
    "\n",
    "original_ref = original_ref.loc[~original_ref[\"chr\"].str.startswith(\"ERCC-\")]\n",
    "\n",
    "## Parse through reference to get gene names and ids\n",
    "orig_ref = original_ref.loc[original_ref[\"type\"]==\"gene\"].copy()\n",
    "orig_ref = parse_df_columns(orig_ref, is_ref=True)\n",
    "\n",
    "## Import disease relevant genes\n",
    "disease_relevant_genes = pd.read_csv(\"../../references/medically_relevant_genes_02-04-2023_UPDATED.tsv\", sep=\"\\t\")\n",
    "\n",
    "## Brain disease genes\n",
    "brain_disease_gene_ids = pd.read_csv(\"../../references/brain_disease_genes_only_IDs.tsv\", sep=\"\\t\")\n",
    "brain_disease_annotations = pd.read_csv(\"../../references/brain_disease_genes_with_disease.tsv\", sep=\"\\t\")\n",
    "\n",
    "## Import AD Genes\n",
    "ad_names = pd.read_csv(\"../../references/AD_gwas_genes.tsv\", sep=\"\\t\")\n",
    "\n",
    "## Create disease relevant list including chromosome\n",
    "disease_relevant_genes_annotated = disease_relevant_genes.merge(orig_ref[[\"gene_id\", \"gene_name\", \"chr\"]], \n",
    "                                                               how=\"inner\", on=[\"gene_id\", \"gene_name\"])\n",
    "\n",
    "## Create list of protein coding genes\n",
    "protein_coding_ref = orig_ref.loc[orig_ref[\"gene_biotype\"] == \"protein_coding\"].copy()\n",
    "\n",
    "## Import and parse through extended annotations\n",
    "ref = pd.read_csv(\"../../data/raw/nextflow_pipeline_output/bambu_discovery/extended_annotations.gtf\", header=None, delimiter=\"\\t\",\n",
    "                        low_memory=False, comment=\"#\", names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"])\n",
    "\n",
    "ref = ref.loc[~ref[\"chr\"].str.startswith(\"ERCC-\")]\n",
    "\n",
    "ref = parse_df_columns(ref, is_ref=False)\n",
    "\n",
    "ref_transcripts = ref.loc[ref[\"type\"] == \"transcript\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb3b2e",
   "metadata": {},
   "source": [
    "# - Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5df7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data for transcript level counts and fix column names\n",
    "\n",
    "df = pd.read_csv(\"../../data/raw/nextflow_pipeline_output/bambu_discovery/counts_transcript.txt\", \n",
    "                           delimiter=\"\\t\", low_memory=False, header=0)\n",
    "\n",
    "df = fix_column_names(df, is_gene=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1c5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate total counts\n",
    "df[\"total_counts\"] = df[df.filter(regex='count').columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e424d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate CPM and drop count columns\n",
    "df = calculate_cpm(df, is_gene=False)\n",
    "\n",
    "df = df[df.columns.drop(list(df.filter(regex='counts')))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c237b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop ERCCs\n",
    "df = df.loc[~df[\"gene_id\"].str.startswith(\"ERCC\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02cefca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate median CPM\n",
    "df[\"median_CPM\"] = df[df.filter(regex='[0-9]_CPM').columns].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3593fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotate transcritps in counts matrix\n",
    "df = df.merge(ref_transcripts[[\"gene_id\", \"transcript_id\", \"chr\"]], on=[\"gene_id\", \"transcript_id\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7f6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create novel transcripts annotations\n",
    "df_novel = df.loc[df[\"transcript_id\"].str.startswith(\"BambuTx\")].copy()\n",
    "df_novel = df_novel.loc[df_novel[\"chr\"] != \"MT\"].copy()\n",
    "df_novel = df_novel[df_novel[\"median_CPM\"] > 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d25921",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create novel mitochondrial transcript dataframe\n",
    "df_novel_mito = df.loc[df[\"transcript_id\"].isin([\"BambuTx1845\", \"BambuTx1846\", \"BambuTx1847\",\n",
    "                                                 \"BambuTx1848\", \"BambuTx1850\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323715d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create final novel dataframe\n",
    "df_novel = pd.concat([df_novel, df_novel_mito])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "082b5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get novel ids\n",
    "df_novel_ids = df_novel[[\"gene_id\", \"transcript_id\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac1c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create known transcripts annotations\n",
    "df_known = df.loc[~(df[\"transcript_id\"].str.startswith(\"BambuTx\"))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31594a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse through reference to get gene names and ids\n",
    "prot_ref = original_ref.loc[original_ref[\"type\"]==\"transcript\"].copy()\n",
    "prot_ref = parse_df_columns(prot_ref, is_ref=True, is_transcript=True)\n",
    "prot_ref = prot_ref.loc[prot_ref[\"transcript_biotype\"] == \"protein_coding\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "264ac6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add all mapt transcripts\n",
    "prot_ref_mapt = prot_ref.loc[prot_ref[\"gene_name\"] == \"MAPT\"].copy()\n",
    "prot_ref_mapt_ids = prot_ref_mapt[[\"gene_id\", \"transcript_id\"]].copy()\n",
    "\n",
    "df_novel_ids = pd.concat([df_novel_ids, prot_ref_mapt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "319e1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter known transcripts\n",
    "df_known = df_known.loc[((df_known[\"chr\"] == \"MT\") | (df_known[\"gene_id\"].isin(df_novel_ids[\"gene_id\"])))].copy()\n",
    "df_known = df_known.loc[df_known[\"transcript_id\"].isin(prot_ref[\"transcript_id\"])].copy()\n",
    "df_known_ids = df_known[[\"gene_id\", \"transcript_id\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3157cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop any duplicates\n",
    "df_novel_ids.drop_duplicates(inplace=True)\n",
    "df_known_ids.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb34246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all ids for relevant transcripts\n",
    "all_ids = pd.concat([df_known_ids, df_novel_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b63bd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and parse through extended annotations\n",
    "ref = pd.read_csv(\"../../data/raw/nextflow_pipeline_output/bambu_discovery/extended_annotations.gtf\", header=None, delimiter=\"\\t\",\n",
    "                        low_memory=False, comment=\"#\", names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"])\n",
    "\n",
    "ref = parse_df_columns(ref, is_ref=False, delete_other=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8de285e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create final reference for mass spec from cell line\n",
    "ref_new = ref.loc[ref[\"transcript_id\"].isin(df_novel_ids[\"transcript_id\"])].copy()\n",
    "\n",
    "## Only keep relevant columns\n",
    "ref_new = ref_new[['chr', 'source', 'type', 'start', 'end', 'dot_1', 'strand', 'dot_2', 'other']].copy()\n",
    "\n",
    "## Output reference\n",
    "ref_new.to_csv(\"../../data/processed/other/mass_spec_annotations/NEW_annotation_for_cell_line_mass_spec.gtf\", \n",
    "                 index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d411a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create final reference for mass spec from cell line\n",
    "ref_known = ref.loc[ref[\"transcript_id\"].isin(df_known_ids[\"transcript_id\"])].copy()\n",
    "\n",
    "## Only keep relevant columns\n",
    "ref_known = ref_known[['chr', 'source', 'type', 'start', 'end', 'dot_1', 'strand', 'dot_2', 'other']].copy()\n",
    "\n",
    "## Output reference\n",
    "ref_known.to_csv(\"../../data/processed/other/mass_spec_annotations/KNOWN_annotation_for_cell_line_mass_spec.gtf\", \n",
    "                 index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be7569de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create final reference for mass spec from cell line\n",
    "ref_final = ref.loc[ref[\"transcript_id\"].isin(all_ids[\"transcript_id\"])].copy()\n",
    "\n",
    "## Only keep relevant columns\n",
    "ref_final = ref_final[['chr', 'source', 'type', 'start', 'end', 'dot_1', 'strand', 'dot_2', 'other']].copy()\n",
    "\n",
    "## Output reference\n",
    "ref_final.to_csv(\"../../data/processed/other/mass_spec_annotations/ALL_annotation_for_cell_line_mass_spec.gtf\", \n",
    "                 index=False, header=False, sep=\"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
