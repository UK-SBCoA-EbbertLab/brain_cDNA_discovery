{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e81ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd065cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: parse_dff_columns\n",
    "\n",
    "purpose: parsing the last aggregate column of the gtf/gff3 into useful columns and cleaning non-relevant columns\n",
    "\n",
    "input: dataframe containining \"raw\" gtf/gff\n",
    "\n",
    "output: dataframe containing gtf with useful columns [\"gene_id\", \"transcript_id\", etc...]\n",
    "'''\n",
    "\n",
    "def parse_df_columns(df, is_ref=True, is_transcript=False, is_exon=False):\n",
    "\n",
    "    dff = df.copy()\n",
    "    \n",
    "    \n",
    "    if is_ref:\n",
    "\n",
    "        ## Get gene ids\n",
    "        dff[\"gene_id\"] = dff[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "        \n",
    "        ## Get gene names\n",
    "        dff[\"gene_name\"] = dff[\"other\"].str.split(\"gene_name \\\"\", expand=True)[1].str.split('\\\";', expand=True)[0]\n",
    "        \n",
    "        ## Get get transcript biotype\n",
    "        dff[\"gene_biotype\"] = dff[\"other\"].str.split('gene_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        if is_transcript:\n",
    "            dff[\"transcript_id\"] = dff[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            dff[\"transcript_biotype\"] = dff[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        if is_exon:\n",
    "            dff[\"transcript_id\"] = dff[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            dff[\"transcript_biotype\"] = dff[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            dff[\"exon_number\"] = dff[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "            \n",
    "        ## Drop \"other\" column\n",
    "        dff.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Get gene ids\n",
    "        dff[\"gene_id\"] = dff[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "\n",
    "        ## Get transcript ids\n",
    "        dff[\"transcript_id\"] = dff[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Get exon number\n",
    "        dff[\"exon_number\"] = dff[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        dff.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "\n",
    "    for col in dff.columns:\n",
    "        dff.loc[dff[col].isnull(), col] = np.NaN\n",
    "        \n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b0b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "## Open original reference\n",
    "original_ref = pd.read_csv(\"../references/Homo_sapiens.GRCh38.107_ERCC.gtf\", header=None, delimiter=\"\\t\", low_memory=False, \n",
    "                       names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"], comment=\"#\")\n",
    "\n",
    "\n",
    "\n",
    "## Bambu reference with novel and annotated transcripts\n",
    "bambu_ref = pd.read_csv(\"../data/raw/nextflow_pipeline_output/bambu_discovery/extended_annotations.gtf\", header=None, delimiter=\"\\t\",\n",
    "                        low_memory=False, names=[\"chr\", \"source\", \"type\", \"start\", \"end\", \"dot_1\", \"strand\", \"dot_2\", \"other\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1d1206",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'other'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m orig_ref_transcripts \u001b[38;5;241m=\u001b[39m original_ref\u001b[38;5;241m.\u001b[39mloc[original_ref[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m orig_ref_transcripts \u001b[38;5;241m=\u001b[39m parse_df_columns(orig_ref_transcripts, is_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m bambu_ref \u001b[38;5;241m=\u001b[39m \u001b[43mparse_df_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbambu_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m bambu_ref_transcripts \u001b[38;5;241m=\u001b[39m bambu_ref\u001b[38;5;241m.\u001b[39mloc[bambu_ref[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mparse_df_columns\u001b[0;34m(df, is_ref, is_transcript, is_exon)\u001b[0m\n\u001b[1;32m     38\u001b[0m     dff\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_2\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m## Get gene ids\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdff\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mother\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([^ \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m]*$)\u001b[39m\u001b[38;5;124m\"\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m## Get transcript ids\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscript_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscript_id \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/conda/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'other'"
     ]
    }
   ],
   "source": [
    "orig_ref_transcripts = original_ref.loc[original_ref[\"type\"]==\"gene\"].copy()\n",
    "orig_ref_transcripts = parse_df_columns(orig_ref_transcripts, is_ref=True)\n",
    "\n",
    "\n",
    "\n",
    "bambu_ref = parse_df_columns(bambu_ref, is_ref=False)\n",
    "bambu_ref_transcripts = bambu_ref.loc[bambu_ref[\"type\"]==\"transcript\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [\"BambuTx1025\", \"BambuTx1138\", \"BambuTx1322\", \"BambuTx1324\", \"BambuTx151\", \"BambuTx1711\", \"BambuTx1845\",\n",
    "\"BambuTx1879\", \"BambuTx2506\", \"BambuTx2804\", \"BambuTx2703\", \"BambuTx1847\", \"BambuTx1850\", \"BambuTx956\",\n",
    "\"BambuTx2603\", \"BambuTx594\",  \"BambuTx2813\", \"BambuTx860\", \"BambuTx861\", \"BambuTx1474\", \"BambuTx1473\",\n",
    "\"BambuTx978\", \"BambuTx977\", \"BambuTx458\", \"BambuTx1803\", \"BambuTx1879\", \"BambuTx1850\", \"BambuTx2710\",\n",
    "\"BambuTx545\", \"BambuTx123\", \"BambuTx1323\", \"BambuTx1607\", \"BambuTx1602\", \"BambuTx2900\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c506bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambu_ref = bambu_ref.loc[bambu_ref[\"transcript_id\"].isin(keep)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95874c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambu_ref_final = bambu_ref.merge(orig_ref_transcripts[[\"gene_id\", \"gene_name\"]], on=\"gene_id\", how=\"left\")\n",
    "\n",
    "bambu_ref_final = bambu_ref_final[[\"gene_name\", \"gene_id\", \"transcript_id\"]].copy()\n",
    "\n",
    "bambu_ref_final['gene_name'].fillna(bambu_ref_final['gene_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f4f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambu_ref_final.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25bd6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bambu_ref_final.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
