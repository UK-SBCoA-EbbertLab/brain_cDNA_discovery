{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf950391",
   "metadata": {},
   "source": [
    "# Import libraries and define functions + Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efbddefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26963919",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "name: relative_transcript_abundance\n",
    "\n",
    "purpose: calculate relative transcript abundance\n",
    "\n",
    "input: a dataframe with a ref_gene_id column identifying the transcript gene of origin and a cov columns with \n",
    "the coverage for the transcripts.\n",
    "\n",
    "output: the same dataframe with a relative abundance column added\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def relative_transcript_abundance(df):\n",
    "    \n",
    "    dff = df.copy()\n",
    "    \n",
    "    first=True\n",
    "    \n",
    "    for col in dff.filter(regex='sample').columns:\n",
    "        \n",
    "        col_gene_name = col + \"_total_gene_expression\"\n",
    "        col_relative_abundance = col + \"_relative_abundance\"\n",
    "    \n",
    "        dff_sums = dff[[\"gene_id\", col]].groupby(\"gene_id\").sum()\n",
    "\n",
    "        dff_sums[col_gene_name] = dff_sums[col].copy()\n",
    "\n",
    "        dff_sums.drop(columns=col, inplace=True)\n",
    "\n",
    "        if first:\n",
    "            merged_dff = pd.merge(dff, dff_sums, how='inner', on=\"gene_id\")\n",
    "            merged_dff[col_relative_abundance] = ((merged_dff[col]/merged_dff[col_gene_name]) * 100)\n",
    "            \n",
    "        else:\n",
    "            merged_dff = pd.merge(merged_dff, dff_sums, how='inner', on=\"gene_id\")\n",
    "            merged_dff[col_relative_abundance] = ((merged_dff[col]/merged_dff[col_gene_name]) * 100)\n",
    "        \n",
    "        first=False\n",
    "        \n",
    "    merged_dff.fillna(value=0, inplace=True)\n",
    "        \n",
    "    return merged_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94f624b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: fix_column_names\n",
    "\n",
    "purpose: Fixing the column names, making them smaller, informative, and consistent\n",
    "\n",
    "input: The raw counts dataframe for either genes or transcripts \n",
    "\n",
    "output: Same dataframe with improved column names\n",
    "'''\n",
    "\n",
    "def fix_column_names(df, is_gene=False):\n",
    "    \n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Check if this is a gene counts object\n",
    "    if is_gene:\n",
    "        \n",
    "        ## Get count column names and create list of new column names\n",
    "        count_columns = dff.columns.tolist()\n",
    "        list_new_names = [\"gene_id\"]\n",
    "        \n",
    "        ## gene_id comes in as index for gene counts data, make it into the first column instead\n",
    "        dff[\"gene_id\"] = dff.index\n",
    "        cols = list(dff.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        dff = dff[cols]\n",
    "        dff.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    ## If it is a transcript dataset\n",
    "    else:\n",
    "        ## Set count columns and create list of new names\n",
    "        count_columns = dff.columns[2:].tolist()\n",
    "        list_new_names = [ \"transcript_id\", \"gene_id\"]\n",
    "    \n",
    "    ## Fix names one by one and add to list of new names\n",
    "    for col in count_columns:\n",
    "        col = col.split(\"_mapped\")[0] + \"_counts\"\n",
    "        list_new_names.append(col)\n",
    "    \n",
    "    ## Rename columns\n",
    "    dff.columns = list_new_names\n",
    "    \n",
    "    return dff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f88fff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: parse_df_columns\n",
    "\n",
    "purpose: parsing the last aggregate column of the gtf/gff3 into useful columns and cleaning non-relevant columns\n",
    "\n",
    "input: dataframe containining \"raw\" gtf/gff\n",
    "\n",
    "output: dataframe containing gtf with useful columns [\"gene_id\", \"transcript_id\", etc...]\n",
    "'''\n",
    "\n",
    "def parse_df_columns(df, is_ref=True, is_transcript=False, is_prot=False, delete_other=True):\n",
    "\n",
    "    if is_ref:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "        \n",
    "        ## Get gene names\n",
    "        df[\"gene_name\"] = df[\"other\"].str.split(\"gene_name \\\"\", expand=True)[1].str.split('\\\";', expand=True)[0]\n",
    "        \n",
    "        ## Get get transcript biotype\n",
    "        df[\"gene_biotype\"] = df[\"other\"].str.split('gene_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "        \n",
    "        ## If is transcript get transcript id and transcript biotype\n",
    "        if is_transcript:\n",
    "            df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            df[\"transcript_biotype\"] = df[\"other\"].str.split('transcript_biotype \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "            \n",
    "            ## If is prot get protein_id\n",
    "            if is_prot:\n",
    "                df[\"protein_id\"] = df[\"other\"].str.split('protein_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"ccds_id\"] = df[\"other\"].str.split('ccds_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "                df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        ## Get gene ids\n",
    "        df[\"gene_id\"] = df[\"other\"].str.split('\";', expand=True)[0].str.extract(\"([^ \\\"]*$)\", expand=True)\n",
    "\n",
    "        ## Get transcript ids\n",
    "        df[\"transcript_id\"] = df[\"other\"].str.split('transcript_id \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Get exon number\n",
    "        df[\"exon_number\"] = df[\"other\"].str.split('exon_number \"', expand=True)[1].str.split('\"', expand=True)[0]\n",
    "\n",
    "        ## Drop \"other\" column\n",
    "        if delete_other:\n",
    "            df.drop(columns=[\"other\", \"dot_1\", \"dot_2\"], inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df.loc[df[col].isnull(), col] = np.NaN\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e75e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function name: calculate_cpm\n",
    "\n",
    "purpose: Calculate CPM for the each sample given\n",
    "\n",
    "input: Counts dataset\n",
    "\n",
    "output: Counts dataset with CPM columns as well\n",
    "'''\n",
    "\n",
    "def calculate_cpm(df, is_gene=False):\n",
    "    \n",
    "    dff = df.copy()\n",
    "\n",
    "    ## Set count columns if dataframe is gene counts\n",
    "    if is_gene:\n",
    "        count_columns = dff.columns[1:].tolist()\n",
    "    \n",
    "    ## Set count columns if dataframe is transcript counts\n",
    "    else:\n",
    "        count_columns = dff.columns[2:].tolist()\n",
    "\n",
    "    ## Loop through counts columns to calculate CPM and add to the dataframe\n",
    "    cpm_columns = {}\n",
    "\n",
    "    for col in count_columns:\n",
    "        rounded_col = round(dff[col], 2)\n",
    "        cpm_name = col.replace(\"_counts\", \"_CPM\")\n",
    "        cpm_columns[cpm_name] = round(((rounded_col/(rounded_col.sum())) * 1000000), 2)\n",
    "\n",
    "    new_data = {**dff.round(2).to_dict(orient='series'), **cpm_columns}\n",
    "    dff = pd.DataFrame(new_data)\n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce71425",
   "metadata": {},
   "source": [
    "## Import data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f21b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "\n",
    "df_qpcr = pd.read_csv(\"../../../data/raw/RT-qPCR/cyc1_RT-qPCR.csv\")\n",
    "\n",
    "df_ont = pd.read_csv(\"../../../data/raw/nextflow_pipeline_output/bambu_discovery/counts_transcript.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b20aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix column names and calculate CPM\n",
    "df_ont = fix_column_names(df_ont, is_gene=False)\n",
    "df_ont = calculate_cpm(df_ont, is_gene=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b3a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop counts columns\n",
    "df_ont.drop(columns=df_ont.filter(regex=\"counts\").columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc7ec775",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename samples from long-read sequencing\n",
    "\n",
    "for col in df_ont.columns:\n",
    "    if col.startswith(\"sample\"):\n",
    "        df_ont.rename(columns={col: col.split(\"_PA\")[0]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16ba0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop useless stuff from qPCR\n",
    "\n",
    "df_qpcr.drop(columns=[\"Unnamed: 9\", \"Unnamed: 10\"], inplace=True)\n",
    "\n",
    "df_qpcr.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79cd3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix sample column\n",
    "\n",
    "df_qpcr[\"Sample\"] = \"sample_\" + df_qpcr[\"Sample \"].astype(str).str.split(\".\", expand=True)[0]\n",
    "\n",
    "df_qpcr.drop(columns=\"Sample \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a914a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transverse qPCR dataframe\n",
    "\n",
    "df_qpcr_T = df_qpcr.drop(columns=\"Sample\").T\n",
    "df_qpcr_T.columns = df_qpcr[\"Sample\"].to_list()\n",
    "df_qpcr = df_qpcr_T.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05092e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep relevant transcript on ONT data\n",
    "\n",
    "trascript_list = [\"BambuTx1879\", \"ENST00000361661\", \"ENST00000378069\", \"ENST00000622731\",\n",
    "                                     \"BambuTx1845\", \"BambuTx1847\", \"ENST00000387347\", \"BambuTx1322\"]\n",
    "\n",
    "df_ont = df_ont.loc[df_ont[\"transcript_id\"].isin(trascript_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "725f7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe with relevant information\n",
    "\n",
    "transcripts_dict = {\"transcript_id\": [\"BambuTx1879\", \"ENST00000361661\", \"ENST00000378069\", \"ENST00000622731\",\n",
    "                                     \"BambuTx1845\", \"BambuTx1847\", \"ENST00000387347\", \"BambuTx1322\"],\n",
    "                   \"gene_id\": [\"ENSG00000069535\", \"ENSG00000145217\", \"ENSG00000069535\", \"ENSG00000145217\",\n",
    "                              \"ENSG00000210082\", \"ENSG00000210082\", \"ENSG00000210082\", \"ENSG00000145217\"],\n",
    "                   \"gene_name\": [\"MAOB\", \"SLC26A1\", \"MAOB\", \"SLC26A1\",\n",
    "                                \"MT-RNR2\", \"MT-RNR2\", \"MT-RNR2\", \"SLC26A1\"]}\n",
    "\n",
    "df_transcript_info = pd.DataFrame(data=transcripts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "074de37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make transcript_id a column of qPCR dataframe\n",
    "df_qpcr.reset_index(names=\"transcript_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a49d3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop gene_id in ONT dataframe\n",
    "\n",
    "df_ont.drop(columns=\"gene_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d2ad9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add gene name and transcript name information to dataframe\n",
    "\n",
    "df_qpcr = df_qpcr.merge(df_transcript_info, on=\"transcript_id\", how=\"inner\")\n",
    "\n",
    "df_ont = df_ont.merge(df_transcript_info, on=\"transcript_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ccf9aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>sample_579</th>\n",
       "      <th>sample_1131</th>\n",
       "      <th>sample_1218</th>\n",
       "      <th>sample_1304</th>\n",
       "      <th>sample_1271</th>\n",
       "      <th>sample_5356</th>\n",
       "      <th>sample_1163</th>\n",
       "      <th>sample_5295</th>\n",
       "      <th>sample_5292</th>\n",
       "      <th>sample_1092</th>\n",
       "      <th>sample_1186</th>\n",
       "      <th>sample_1291</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BambuTx1322</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.45</td>\n",
       "      <td>ENSG00000145217</td>\n",
       "      <td>SLC26A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BambuTx1845</td>\n",
       "      <td>37.63</td>\n",
       "      <td>1.07</td>\n",
       "      <td>18.76</td>\n",
       "      <td>1.65</td>\n",
       "      <td>43.42</td>\n",
       "      <td>1.31</td>\n",
       "      <td>54.74</td>\n",
       "      <td>101.16</td>\n",
       "      <td>39.21</td>\n",
       "      <td>7.53</td>\n",
       "      <td>14.25</td>\n",
       "      <td>41.55</td>\n",
       "      <td>ENSG00000210082</td>\n",
       "      <td>MT-RNR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BambuTx1847</td>\n",
       "      <td>277.92</td>\n",
       "      <td>11.42</td>\n",
       "      <td>122.55</td>\n",
       "      <td>60.76</td>\n",
       "      <td>115.28</td>\n",
       "      <td>79.00</td>\n",
       "      <td>179.48</td>\n",
       "      <td>428.53</td>\n",
       "      <td>151.97</td>\n",
       "      <td>74.96</td>\n",
       "      <td>106.54</td>\n",
       "      <td>155.12</td>\n",
       "      <td>ENSG00000210082</td>\n",
       "      <td>MT-RNR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BambuTx1879</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.29</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.47</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.73</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>15.40</td>\n",
       "      <td>ENSG00000069535</td>\n",
       "      <td>MAOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000361661</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ENSG00000145217</td>\n",
       "      <td>SLC26A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_id  sample_579  sample_1131  sample_1218  sample_1304  \\\n",
       "0      BambuTx1322        1.47         0.49         1.63         0.68   \n",
       "1      BambuTx1845       37.63         1.07        18.76         1.65   \n",
       "2      BambuTx1847      277.92        11.42       122.55        60.76   \n",
       "3      BambuTx1879        4.30         1.29         6.71         0.68   \n",
       "4  ENST00000361661        0.01         2.18         0.00         0.34   \n",
       "\n",
       "   sample_1271  sample_5356  sample_1163  sample_5295  sample_5292  \\\n",
       "0         0.53         1.14         1.75         2.91         0.54   \n",
       "1        43.42         1.31        54.74       101.16        39.21   \n",
       "2       115.28        79.00       179.48       428.53       151.97   \n",
       "3         4.76         2.47         6.17         6.16         6.73   \n",
       "4         0.04         0.73         0.06         0.06         0.18   \n",
       "\n",
       "   sample_1092  sample_1186  sample_1291          gene_id gene_name  \n",
       "0         1.47         0.72         5.45  ENSG00000145217   SLC26A1  \n",
       "1         7.53        14.25        41.55  ENSG00000210082   MT-RNR2  \n",
       "2        74.96       106.54       155.12  ENSG00000210082   MT-RNR2  \n",
       "3         3.43         0.54        15.40  ENSG00000069535      MAOB  \n",
       "4         0.08         0.36         0.04  ENSG00000145217   SLC26A1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ee4cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate relative abundance\n",
    "\n",
    "df_qpcr = relative_transcript_abundance(df_qpcr)\n",
    "\n",
    "df_ont = relative_transcript_abundance(df_ont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbdfc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create melted dataframe for ONT\n",
    "\n",
    "drop_columns_ont =  df_ont.filter(regex=\"total\").columns.to_list()\n",
    "\n",
    "drop_columns_ont = drop_columns_ont + [\"sample_579\",\"sample_1131\", \"sample_1218\", \"sample_1304\", \n",
    "                                                        \"sample_1271\", \"sample_5356\", \"sample_1163\", \"sample_5295\", \n",
    "                                                        \"sample_5292\", \"sample_1092\", \"sample_1186\", \"sample_1291\"]\n",
    "\n",
    "\n",
    "df_ont_melted = df_ont.drop(columns=drop_columns_ont)\n",
    "\n",
    "df_ont_melted = df_ont_melted.melt(id_vars=['gene_id', \"gene_name\", \"transcript_id\"],\n",
    "                                   var_name='Sample', value_name='relative_abundance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c16322",
   "metadata": {},
   "outputs": [],
   "source": [
    "['sample_5356', 'sample_5292', 'sample_1092', 'sample_1186']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
